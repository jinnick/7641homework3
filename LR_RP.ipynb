{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import letter_recognition as data\n",
    "import numpy as np\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import random_projection\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc1=[]\n",
    "for i in range(1, 11):\n",
    "    rp1 = random_projection.GaussianRandomProjection(n_components=i, random_state=10)\n",
    "    X_rp1 =rp1.fit_transform(data.X_train)\n",
    "    #clf = DecisionTreeClassifier(max_depth=5)\n",
    "    clf1 = KMeans(init='k-means++',n_clusters=26)\n",
    "    clf1.fit(X_rp1)\n",
    "    pred1 = clf1.labels_\n",
    "    if accuracy_score(pred1,data.y_train) < 0.5:\n",
    "        accuracyscore = 1 - accuracy_score(pred1,data.y_train)\n",
    "    if accuracy_score(pred1,data.y_train) > 0.5:\n",
    "        accuracyscore = accuracy_score(pred1,data.y_train)\n",
    "    acc1.append(accuracyscore)\n",
    "print(acc1)\n",
    "\n",
    "acc2=[]\n",
    "for i in range(1, 11):\n",
    "    rp2 = random_projection.SparseRandomProjection(n_components=i, random_state=10)\n",
    "    X_rp2 =rp2.fit_transform(data.X_train)\n",
    "    #clf = DecisionTreeClassifier(max_depth=5)\n",
    "    clf2 = KMeans(init='k-means++',n_clusters=26)\n",
    "    clf2.fit(X_rp2)\n",
    "    pred2 = clf2.labels_\n",
    "    if accuracy_score(pred2,data.y_train) < 0.5:\n",
    "        accuracyscore = 1 - accuracy_score(pred2,data.y_train)\n",
    "    if accuracy_score(pred2,data.y_train) > 0.5:\n",
    "        accuracyscore = accuracy_score(pred2,data.y_train)\n",
    "    acc2.append(accuracyscore)\n",
    "print(acc2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1, 11), acc1, color='r', label='Gaussian Random Projection')\n",
    "plt.plot(range(1, 11), acc2, color='g', label='Sparse Random Projection')\n",
    "\n",
    "plt.xlabel('Random Projection Components',fontsize=18)\n",
    "plt.ylabel('Accuracy_Score',fontsize=18)\n",
    "plt.title('Letter_Recognition(RP_Kmeans_Accuracy)',fontsize=14)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = random_projection.SparseRandomProjection(n_components=7, random_state=10)\n",
    "X_rp =rp.fit_transform(data.X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "Sum_of_squared_distances = []\n",
    "K = range(1,31)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km = km.fit(X_rp)\n",
    "    Sum_of_squared_distances.append(km.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k(number of clusters)',fontsize=18)\n",
    "plt.ylabel('SSE',fontsize=18)\n",
    "plt.title('Letter_Recognition(RP_Kmeans_SSE)',fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "homogeneity_scores=[]\n",
    "clusters=range(1,31)\n",
    "for k in clusters:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km = km.fit(X_rp)\n",
    "    lable = km.labels_\n",
    "    homogeneity_scores.append(metrics.homogeneity_score(data.y_train,lable ))\n",
    "plt.plot(clusters, homogeneity_scores,'bo-')\n",
    "plt.xlabel('k(Number of clusters)',fontsize=18)\n",
    "plt.ylabel('Homogeneity Score',fontsize=18)\n",
    "plt.title('Letter_Recognition(RP_Kmeans_Homogeneity Score)',fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "completeness_scores=[]\n",
    "clusters=range(1,31)\n",
    "for k in clusters:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km = km.fit(X_rp)\n",
    "    lable = km.labels_\n",
    "    completeness_scores.append(metrics.completeness_score(data.y_train,lable ))\n",
    "plt.plot(clusters, completeness_scores,'g^-')\n",
    "plt.xlabel('k(Number of clusters)',fontsize=18)\n",
    "plt.ylabel('Completeness Score',fontsize=18)\n",
    "plt.title('Letter_Recognition(RP_Kmeans_Completeness Score)',fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import random_projection\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc2=[]\n",
    "for i in range(1, 31):\n",
    "    rp2 = random_projection.SparseRandomProjection(n_components=i, random_state=10)\n",
    "    X_rp2 =rp1.fit_transform(X_scaled)\n",
    "    #clf = DecisionTreeClassifier(max_depth=5)\n",
    "    clf2 = KMeans(init='k-means++',n_clusters=2)\n",
    "    clf2.fit(X_rp2)\n",
    "    pred2 = clf2.labels_\n",
    "    if accuracy_score(pred2,y) < 0.5:\n",
    "        accuracyscore = 1 - accuracy_score(pred2,y)\n",
    "    if accuracy_score(pred2,y) > 0.5:\n",
    "        accuracyscore = accuracy_score(pred2,y)\n",
    "    acc2.append(accuracyscore)\n",
    "print(acc2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import random_projection\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc1=[]\n",
    "for i in range(1, 11):\n",
    "    rp1 = random_projection.GaussianRandomProjection(n_components=i, random_state=10)\n",
    "    X_rp1 =rp1.fit_transform(data.X_train)\n",
    "    #clf = DecisionTreeClassifier(max_depth=5)\n",
    "    clf1 = GMM(covariance_type = 'full')\n",
    "    clf1.set_params(n_components=2)\n",
    "    pred1 = clf1.fit_predict(X_rp1)\n",
    "    if accuracy_score(pred1,data.y_train) < 0.5:\n",
    "        accuracyscore = 1 - accuracy_score(pred1,data.y_train)\n",
    "    if accuracy_score(pred1,data.y_train) > 0.5:\n",
    "        accuracyscore = accuracy_score(pred1,data.y_train)\n",
    "    acc1.append(accuracyscore)\n",
    "print(acc1)\n",
    "\n",
    "acc2=[]\n",
    "for i in range(1, 11):\n",
    "    rp2 = random_projection.SparseRandomProjection(n_components=i, random_state=10)\n",
    "    X_rp2 =rp2.fit_transform(data.X_train)\n",
    "    #clf = DecisionTreeClassifier(max_depth=5)\n",
    "    clf2 = GMM(covariance_type = 'full')\n",
    "    clf2.set_params(n_components=2)\n",
    "    pred2 = clf1.fit_predict(X_rp2)\n",
    "    if accuracy_score(pred2,data.y_train) < 0.5:\n",
    "        accuracyscore = 1 - accuracy_score(pred2,data.y_train)\n",
    "    if accuracy_score(pred2,data.y_train) > 0.5:\n",
    "        accuracyscore = accuracy_score(pred2,data.y_train)\n",
    "    acc2.append(accuracyscore)\n",
    "print(acc2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1, 11), acc1, color='r', label='Gaussian Random Projection')\n",
    "plt.plot(range(1, 11), acc2, color='g', label='Sparse Random Projection')\n",
    "\n",
    "plt.xlabel('Random Projection Components',fontsize=18)\n",
    "plt.ylabel('Accuracy_Score',fontsize=18)\n",
    "plt.title('Letter_Recognition(RP_GMM_Accuracy)',fontsize=14)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = random_projection.SparseRandomProjection(n_components=4, random_state=10)\n",
    "X_rp =rp.fit_transform(data.X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "ll=[]\n",
    "bic=[]\n",
    "homogeinity_scores=[]\n",
    "completeness_scores=[]\n",
    "clusters=range(1,31)\n",
    "model = GMM(covariance_type = 'full')\n",
    "for k in clusters:\n",
    "            model.set_params(n_components=k)\n",
    "            model.fit(X_rp)\n",
    "            labels = model.predict(X_rp)\n",
    "            ll.append(model.score(X_rp))\n",
    "            bic.append(model.bic(X_rp))\n",
    "            homogeinity_scores.append(metrics.homogeneity_score(data.y_train,labels))\n",
    "            completeness_scores.append(metrics.completeness_score(data.y_train,labels))\n",
    "print(bic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(clusters, ll, color='blue')\n",
    "plt.xlabel('k(Number of clusters)',fontsize=18)\n",
    "plt.ylabel('Log Probability',fontsize=18);\n",
    "plt.title('Letter_Recognition(RP_GMM_Full_Covariance_Log_Probability)',fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(clusters, homogeneity_scores,'bo-')\n",
    "plt.xlabel('k(Number of clusters)',fontsize=18)\n",
    "plt.ylabel('Homogeneity Score',fontsize=18)\n",
    "plt.title('Letter_Recognition(RP_GMM_Full_Covariance_Homogeneity Score)',fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(clusters, completeness_scores,'g^-')\n",
    "plt.xlabel('k(Number of clusters)',fontsize=18)\n",
    "plt.ylabel('Completeness Score',fontsize=18)\n",
    "plt.title('Letter_Recognition(RP_GMM_Full_Covariance_Completeness Score)',fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic2=[595681.06407176226, 553912.25273492467, 530720.20033587876, 503221.70012021047, 447283.22086607729, 451825.70017588028, 443626.98389246903, 433674.53006708872, 416415.4066152898, 408596.82664275123, 376019.60288024443, 368610.86938890023, 336976.97505033674, 333373.30356770469, 329729.61742094712, 324451.01867622038, 324126.36980339658, 312213.14488639543, 314093.54577524349, 322679.1090524015, 359128.46439727867, 307443.77934851486, 305634.81837944919, 291955.04050467932, 287172.57117379352, 328037.28389575653, 323025.78966321622, 321714.43428913783, 290333.67651900218, 275310.26912355283]\n",
    "plt.plot(clusters, bic,'g^-',label='RP BIC')\n",
    "plt.plot(clusters, bic2,'bo-',label='RAW BIC')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('k(Number of clusters)',fontsize=18)\n",
    "plt.ylabel('BIC_score',fontsize=18)\n",
    "plt.title('Letter_Recognition(GMM_BIC VS RP_GMM_BIC)',fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
